{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 12,083,736 implicit ratings\n",
      "Unique users: 162,381\n",
      "Unique products: 35,922\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.models.collaborative_filtering import CollaborativeFilteringModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# ====================== Load Data ======================\n",
    "implicit_ratings = pd.read_csv(\"../data/processed/implicit_ratings.csv\")\n",
    "products = pd.read_csv(\"../data/raw/products.csv\")\n",
    "\n",
    "print(f\"Loaded {len(implicit_ratings):,} implicit ratings\")\n",
    "print(f\"Unique users: {implicit_ratings['user_id'].nunique():,}\")\n",
    "print(f\"Unique products: {implicit_ratings['product_id'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train: 9,668,476 ratings\n",
      "Test: 2,415,260 ratings\n"
     ]
    }
   ],
   "source": [
    "# ====================== Train-Test Split ======================\n",
    "# Split by user to ensure fair evaluation\n",
    "users = implicit_ratings['user_id'].unique()\n",
    "train_users, test_users = train_test_split(users, test_size=0.2, random_state=42)\n",
    "\n",
    "train_ratings = implicit_ratings[implicit_ratings['user_id'].isin(train_users)]\n",
    "test_ratings = implicit_ratings[implicit_ratings['user_id'].isin(test_users)]\n",
    "\n",
    "print(f\"\\nTrain: {len(train_ratings):,} ratings\")\n",
    "print(f\"Test: {len(test_ratings):,} ratings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train users: 162381\n",
      "Test users: 162381\n",
      "User overlap: 1.0\n",
      "Test rows: 2353359 Train rows: 9730377\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = implicit_ratings.copy()\n",
    "\n",
    "# 只保留交互数>=2 的用户（否则没法既 train 又 test）\n",
    "cnt = df.groupby(\"user_id\").size()\n",
    "eligible_users = cnt[cnt >= 2].index\n",
    "df = df[df[\"user_id\"].isin(eligible_users)].copy()\n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "def per_user_split(g, test_ratio=0.2):\n",
    "    n = len(g)\n",
    "    k = max(1, int(np.floor(test_ratio * n)))\n",
    "    test_idx = rng.choice(g.index, size=k, replace=False)\n",
    "    g_test = g.loc[test_idx]\n",
    "    g_train = g.drop(test_idx)\n",
    "    return g_train, g_test\n",
    "\n",
    "train_list, test_list = [], []\n",
    "for _, g in df.groupby(\"user_id\"):\n",
    "    tr, te = per_user_split(g, test_ratio=0.2)\n",
    "    train_list.append(tr)\n",
    "    test_list.append(te)\n",
    "\n",
    "train_ratings = pd.concat(train_list).reset_index(drop=True)\n",
    "test_ratings  = pd.concat(test_list).reset_index(drop=True)\n",
    "\n",
    "# 保证 test 用户都在 train\n",
    "assert test_ratings[\"user_id\"].isin(train_ratings[\"user_id\"]).all()\n",
    "\n",
    "print(\"Train users:\", train_ratings[\"user_id\"].nunique())\n",
    "print(\"Test users:\", test_ratings[\"user_id\"].nunique())\n",
    "print(\"User overlap:\", (test_ratings[\"user_id\"].isin(train_ratings[\"user_id\"]).mean()))\n",
    "print(\"Test rows:\", len(test_ratings), \"Train rows:\", len(train_ratings))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.models.collaborative_filtering:Fitting Collaborative Filtering Model (ALS)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.models.collaborative_filtering:Creating user-item sparse matrix...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAINING ALS MODEL\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.models.collaborative_filtering:Matrix shape: (162381, 35922)\n",
      "INFO:src.models.collaborative_filtering:Sparsity: 99.8332%\n",
      "INFO:src.models.collaborative_filtering:Training ALS model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a963d6e83d4cbdbcffba51513e4117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.models.collaborative_filtering:ALS training complete\n",
      "INFO:src.models.collaborative_filtering:Evaluating model...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 35922 is out of bounds for axis 0 with size 35922",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m als_model\u001b[38;5;241m.\u001b[39mfit(train_ratings)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m metrics_als \u001b[38;5;241m=\u001b[39m \u001b[43mals_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_ratings\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/product-recommendation-engine/notebooks/../src/models/collaborative_filtering.py:227\u001b[0m, in \u001b[0;36mCollaborativeFilteringModel.evaluate\u001b[0;34m(self, test_ratings)\u001b[0m\n\u001b[1;32m    224\u001b[0m product_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproduct_id\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    225\u001b[0m actual \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_rating\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 227\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproduct_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;66;03m# Only evaluate if we can make a prediction\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pred \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/product-recommendation-engine/notebooks/../src/models/collaborative_filtering.py:150\u001b[0m, in \u001b[0;36mCollaborativeFilteringModel.predict\u001b[0;34m(self, user_id, product_id)\u001b[0m\n\u001b[1;32m    147\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_factors[user_idx], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_factors[product_idx]))\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;66;03m# ALS latent factors live on the implicit model\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_factors\u001b[49m\u001b[43m[\u001b[49m\u001b[43muser_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mitem_factors[product_idx]))\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prediction\n",
      "\u001b[0;31mIndexError\u001b[0m: index 35922 is out of bounds for axis 0 with size 35922"
     ]
    }
   ],
   "source": [
    "\n",
    "# ====================== Train ALS Model ======================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING ALS MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "als_model = CollaborativeFilteringModel(\n",
    "    method='als',\n",
    "    n_factors=50,\n",
    "    regularization=0.01,\n",
    "    iterations=5,\n",
    "    alpha=40.0\n",
    ")\n",
    "\n",
    "als_model.fit(train_ratings)\n",
    "\n",
    "# Evaluate\n",
    "metrics_als = als_model.evaluate(test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.models.collaborative_filtering:Fitting Collaborative Filtering Model (SVD)...\n",
      "INFO:src.models.collaborative_filtering:Creating user-item sparse matrix...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAINING SVD MODEL\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.models.collaborative_filtering:Matrix shape: (129904, 35922)\n",
      "INFO:src.models.collaborative_filtering:Sparsity: 99.7928%\n",
      "INFO:src.models.collaborative_filtering:Training SVD model...\n",
      "INFO:src.models.collaborative_filtering:Explained variance ratio: 0.1889\n",
      "INFO:src.models.collaborative_filtering:Evaluating model...\n",
      "INFO:src.models.collaborative_filtering:RMSE: nan\n",
      "INFO:src.models.collaborative_filtering:MAE: nan\n",
      "INFO:src.models.collaborative_filtering:Correlation: 0.0000\n",
      "INFO:src.models.collaborative_filtering:Coverage: 0.00%%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ====================== Train SVD Model ======================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING SVD MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "svd_model = CollaborativeFilteringModel(\n",
    "    method='svd',\n",
    "    n_factors=50\n",
    ")\n",
    "\n",
    "svd_model.fit(train_ratings)\n",
    "\n",
    "# Evaluate\n",
    "metrics_svd = svd_model.evaluate(test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL COMPARISON\n",
      "================================================================================\n",
      "     rmse  mae  correlation  coverage\n",
      "ALS   NaN  NaN          0.0       0.0\n",
      "SVD   NaN  NaN          0.0       0.0\n",
      "\n",
      "✓ Best model: SVD\n"
     ]
    }
   ],
   "source": [
    "# ====================== Compare Models ======================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'ALS': metrics_als,\n",
    "    'SVD': metrics_svd\n",
    "}).T\n",
    "\n",
    "print(comparison)\n",
    "\n",
    "# Choose best model\n",
    "best_model = als_model if metrics_als['rmse'] < metrics_svd['rmse'] else svd_model\n",
    "best_method = 'ALS' if metrics_als['rmse'] < metrics_svd['rmse'] else 'SVD'\n",
    "\n",
    "print(f\"\\n✓ Best model: {best_method}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SAMPLE RECOMMENDATIONS\n",
      "================================================================================\n",
      "\n",
      "Top 10 recommendations for user 117209:\n",
      "1. Organic Peeled Whole Baby Carrots (score: 0.2046)\n",
      "2. Sparkling Lemon Water (score: 0.2024)\n",
      "3. Raspberries (score: 0.1529)\n",
      "4. Boneless Skinless Chicken Breasts (score: 0.1218)\n",
      "5. Pure Sparkling Water (score: 0.1188)\n",
      "6. Organic Baby Arugula (score: 0.1186)\n",
      "7. Organic Red Bell Pepper (score: 0.1106)\n",
      "8. Sparkling Water Berry (score: 0.1104)\n",
      "9. Bartlett Pears (score: 0.1050)\n",
      "10. Feta Cheese Crumbles (score: 0.0999)\n",
      "\n",
      "Products similar to 'Banana':\n",
      "1. Honey Smokehouse Barbecue Sauce (similarity: 0.7311)\n",
      "2. Farmstand Strawberry Banana Juice (similarity: 0.7020)\n",
      "3. Extra Clear for Sensitive Skin Nasal Strips (similarity: 0.6660)\n",
      "4. Colon Health Digestive Health Probiotic Supplement Capsules (similarity: 0.6625)\n",
      "5. Ultra Downy® Mountain Spring™ Liquid Fabric Conditioner 51 Fl oz. 60 loads Fabric Enhancers (similarity: 0.6535)\n",
      "6. Candle, Meadows & Rain (similarity: 0.6302)\n",
      "7. Banana Chocolate Protein Juice Smoothie (similarity: 0.6276)\n",
      "8. Complete Extra White Plus Scope Outlast Fresh Breath Whitening Toothpaste (similarity: 0.6244)\n",
      "9. Home Style Creamy Gouda Bisque With Chicken Soup (similarity: 0.6195)\n",
      "10. Thousand Island Salad Dressing & Dip (similarity: 0.6187)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.models.collaborative_filtering:Model saved to ../models/cf_model_svd.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Model saved to models/cf_model_svd.pkl\n"
     ]
    }
   ],
   "source": [
    "# ====================== Test Recommendations ======================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get a random user\n",
    "sample_user = np.random.choice(train_users)\n",
    "recommendations = best_model.get_recommendations(sample_user, top_n=10)\n",
    "\n",
    "print(f\"\\nTop 10 recommendations for user {sample_user}:\")\n",
    "for i, (product_id, score) in enumerate(recommendations, 1):\n",
    "    product_name = products[products['product_id'] == product_id]['product_name'].values\n",
    "    name = product_name[0] if len(product_name) > 0 else f\"Product {product_id}\"\n",
    "    print(f\"{i}. {name} (score: {score:.4f})\")\n",
    "\n",
    "\n",
    "# ====================== Test Similar Products ======================\n",
    "# Get a popular product\n",
    "popular_products = train_ratings.groupby('product_id').size().nlargest(10).index\n",
    "sample_product = popular_products[0]\n",
    "\n",
    "similar = best_model.get_similar_products(sample_product, top_n=10)\n",
    "\n",
    "product_name = products[products['product_id'] == sample_product]['product_name'].values[0]\n",
    "print(f\"\\nProducts similar to '{product_name}':\")\n",
    "for i, (product_id, similarity) in enumerate(similar, 1):\n",
    "    similar_name = products[products['product_id'] == product_id]['product_name'].values\n",
    "    name = similar_name[0] if len(similar_name) > 0 else f\"Product {product_id}\"\n",
    "    print(f\"{i}. {name} (similarity: {similarity:.4f})\")\n",
    "\n",
    "\n",
    "# ====================== Save Model ======================\n",
    "best_model.save(f\"../models/cf_model_{best_method.lower()}.pkl\")\n",
    "print(f\"\\n✓ Model saved to models/cf_model_{best_method.lower()}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval rows: 2353359 coverage: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 快速评估：只统计 user/item 都 seen 的行，不做 pred>0 过滤\n",
    "seen_mask = test_ratings[\"user_id\"].isin(als_model.user_encoder) & test_ratings[\"product_id\"].isin(als_model.product_encoder)\n",
    "eval_df = test_ratings[seen_mask].copy()\n",
    "print(\"eval rows:\", len(eval_df), \"coverage:\", len(eval_df)/len(test_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns: ['user_id', 'product_id', 'final_rating']\n",
      "shape: (12083736, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>final_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>196</td>\n",
       "      <td>0.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10258</td>\n",
       "      <td>0.892222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10326</td>\n",
       "      <td>0.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12427</td>\n",
       "      <td>0.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13032</td>\n",
       "      <td>0.556667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>13176</td>\n",
       "      <td>0.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>14084</td>\n",
       "      <td>0.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>17122</td>\n",
       "      <td>0.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>25133</td>\n",
       "      <td>0.852500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>26088</td>\n",
       "      <td>0.410000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  product_id  final_rating\n",
       "0        1         196      0.930000\n",
       "1        1       10258      0.892222\n",
       "2        1       10326      0.030000\n",
       "3        1       12427      0.930000\n",
       "4        1       13032      0.556667\n",
       "5        1       13176      0.410000\n",
       "6        1       14084      0.030000\n",
       "7        1       17122      0.030000\n",
       "8        1       25133      0.852500\n",
       "9        1       26088      0.410000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "user_id dtype: int64\n",
      "product_id dtype: int64\n",
      "final_rating dtype: float64\n",
      "\n",
      "#unique users: 162381\n",
      "#unique products: 35922\n",
      "final_rating describe:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    1.208374e+07\n",
       "mean     2.371667e-01\n",
       "std      2.707734e-01\n",
       "min      3.030303e-03\n",
       "25%      1.500000e-02\n",
       "50%      4.285714e-02\n",
       "75%      4.765568e-01\n",
       "max      1.000000e+00\n",
       "Name: final_rating, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "interactions per user (min/median/mean/max): 2 59.0 74.41594767860772 724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "46    1708\n",
       "35    1707\n",
       "34    1703\n",
       "39    1696\n",
       "36    1678\n",
       "43    1677\n",
       "31    1669\n",
       "30    1665\n",
       "42    1664\n",
       "44    1659\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===== Quick peek: implicit_ratings input =====\n",
    "print(\"columns:\", implicit_ratings.columns.tolist())\n",
    "print(\"shape:\", implicit_ratings.shape)\n",
    "display(implicit_ratings.head(10))\n",
    "\n",
    "print(\"\\nuser_id dtype:\", implicit_ratings[\"user_id\"].dtype)\n",
    "print(\"product_id dtype:\", implicit_ratings[\"product_id\"].dtype)\n",
    "print(\"final_rating dtype:\", implicit_ratings[\"final_rating\"].dtype)\n",
    "\n",
    "print(\"\\n#unique users:\", implicit_ratings[\"user_id\"].nunique())\n",
    "print(\"#unique products:\", implicit_ratings[\"product_id\"].nunique())\n",
    "print(\"final_rating describe:\")\n",
    "display(implicit_ratings[\"final_rating\"].describe())\n",
    "\n",
    "# how many interactions per user (distribution glimpse)\n",
    "user_counts = implicit_ratings.groupby(\"user_id\").size()\n",
    "print(\"\\ninteractions per user (min/median/mean/max):\",\n",
    "      user_counts.min(), user_counts.median(), user_counts.mean(), user_counts.max())\n",
    "display(user_counts.value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder user key type example: <class 'numpy.int64'>\n",
      "sample user_id type example: <class 'numpy.int64'>\n",
      "encoder item key type example: <class 'numpy.int64'>\n",
      "sample product_id type example: <class 'numpy.int64'>\n",
      "unseen user rate: 1.0\n",
      "unseen item rate: 0.0\n",
      "both seen rate: 0.0\n",
      ">>> both-seen subset is EMPTY. This means your test has no overlap with train OR id types mismatch.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 抽样\n",
    "sample = test_ratings.sample(n=min(50000, len(test_ratings)), random_state=42)\n",
    "\n",
    "# 关键：明确用 encoder 的 keys，而且做类型对齐\n",
    "train_user_keys = set(als_model.user_encoder.keys())\n",
    "train_item_keys = set(als_model.product_encoder.keys())\n",
    "\n",
    "print(\"encoder user key type example:\", type(next(iter(train_user_keys))))\n",
    "print(\"sample user_id type example:\", type(sample[\"user_id\"].iloc[0]))\n",
    "print(\"encoder item key type example:\", type(next(iter(train_item_keys))))\n",
    "print(\"sample product_id type example:\", type(sample[\"product_id\"].iloc[0]))\n",
    "\n",
    "# 如果类型不同，强制把 sample 的列 cast 成 encoder key 的类型\n",
    "user_key_type = type(next(iter(train_user_keys)))\n",
    "item_key_type = type(next(iter(train_item_keys)))\n",
    "\n",
    "sample_u = sample[\"user_id\"].map(user_key_type)\n",
    "sample_i = sample[\"product_id\"].map(item_key_type)\n",
    "\n",
    "seen_user = sample_u.isin(train_user_keys)\n",
    "seen_item = sample_i.isin(train_item_keys)\n",
    "\n",
    "print(\"unseen user rate:\", 1 - seen_user.mean())\n",
    "print(\"unseen item rate:\", 1 - seen_item.mean())\n",
    "print(\"both seen rate:\", (seen_user & seen_item).mean())\n",
    "\n",
    "both = sample[seen_user & seen_item].copy()\n",
    "if len(both) == 0:\n",
    "    print(\">>> both-seen subset is EMPTY. This means your test has no overlap with train OR id types mismatch.\")\n",
    "else:\n",
    "    preds = []\n",
    "    # 用 cast 后的 id 去 predict\n",
    "    for u, i in zip(sample_u[seen_user & seen_item].values, sample_i[seen_user & seen_item].values):\n",
    "        preds.append(als_model.predict(u, i))\n",
    "    preds = np.array(preds)\n",
    "\n",
    "    print(\"pred count:\", len(preds))\n",
    "    print(\"pred min/median/max:\", float(preds.min()), float(np.median(preds)), float(preds.max()))\n",
    "    print(\"pred <= 0 rate:\", float((preds <= 0).mean()))\n",
    "    print(\"pred == 0 rate:\", float((preds == 0).mean()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
